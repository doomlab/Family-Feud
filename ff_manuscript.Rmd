---
title             : "Gamifying Judgments of Associative Memory"
shorttitle        : "JAM GAME"

author: 
  - name          : "Erin M. Buchanan"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "901 S. National Ave, Springfield, MO, 65897"
    email         : "erinbuchanan@missouristate.edu"
  - name          : "Abigail Van Nuland"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Missouri State University"

authornote: |
  Erin M. Buchanan is an Associate Professor of Quantitative Psychology at Missouri State University, and Abigail Van Nuland is a Masters Degree candidate at Missouri State Univeristy. 

  Enter author note here.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "judgments, word association, metacognition"

#bibliography      : ["r-references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
replace_ampersands: yes
csl               : apa6.csl
---

We are going to write an introduction here about JAM, association, and stuff. 

1) In a traditional free association task, people guess the words...would the numbers help? (a v b)
2) In a JAM task with multiple guesses, they would normally see the words, would expect them to be able to guess better if they know it's descending order, so the D condition would match the normal JAM slope and C should be better (this answers the bounded question).
3) For the non-numbers condition, see if singles or groups are better. Shouldn't more heads be better than one?
4) For the normal JAM task, see if groups are better than singles at guessing the numbers. 

Judgments of associative memory are notoriously poor (Buchanan, 2009; Maki, 2007), where participants over estimate the relationship between word pairs.  In the judgment task, participants are given two words (LOST-FOUND) and asked to rate how many people out of a 100 would list the second word if given the first word.  Participants cannot tell the difference between low and high frequency pairs and tend to judge pairs higher than they should.  The psycholinguistics lab has tried to correct these memory judgments by giving participants various instructions (Buchanan & Maki, in preparation), changing the scales for judgments (Buchanan, data analysis), changing the judgment type (Maki & Buchanan, in preparation), and having participants judge their own ratings over time (Buchanan, data collection).  These manipulations have shown a small effect on judgment ability, mainly to reduce the overall bias to select very large numbers.  The current protocol will examine if judgments are more accurate when the experimental task is more interesting and engaging.  We will be using the game show Family Feud as the experimental procedure because the game show closely matches the judgments of memory paradigm currently used.

```{r setup, include = FALSE}
# Load Libraries ----------------------------------------------------------
library("papaja")
library(moments)
library(reshape)
library(nlme)
library(lme4)
```

# Method

```{r Upload_Data, include = FALSE}
#upload data sets
AB = read.csv("AB_FF_Data.csv")
#View(AB)
CD = read.csv("CD_FF_Data.csv")
#View(CD)
newdata = read.csv("Points.csv")
```

```{r data_screening, include=FALSE}

# Data Screening ----------------------------------------------------------
###AB Set###
##Accuracy
#Categorical Variables
table(AB$Number.of.People) #Includes One Group of One? (delete)
table(AB$Condition, AB$Number.of.People)
AB$Condition[AB$Number.of.People == 1] = "A.1 Single"
table(AB$Condition) #Uneven But No Typos
table(AB$Equal.Participation) #*Will Make No Missing Data
notyposAB = AB

#check for continuous problems, making sure only options are 1 and 0
summary(notyposAB) #Looks Good

#Missing Data
#none

#Outliers
#Don't See How we could do an outlier ananlysis (0 and 1 only options)

##Assumptions
#Linearity
random = rchisq(nrow(notyposAB), 7)
fakeAB = lm(random~., data=notyposAB[ , -c(1,2,3,4)])
standardizedAB = rstudent(fakeAB)
qqnorm(standardizedAB)
abline(0,1) 

#Normality
skewness(notyposAB[ , -c(1,2,3,4)], na.rm=TRUE)
kurtosis(notyposAB[ , -c(1,2,3,4)], na.rm=TRUE)
hist(standardizedAB, breaks=15) #A Bit Skewed, but CLT

##homogeneity and homoscedaticity
fitvalues = scale(fakeAB$fitted.values)
plot(fitvalues, standardizedAB) 
abline(0,0)
abline(v = 0)

###CD Set###
#Accuracy
#Categorical Variables
table(CD$Number.of.People) #Looks Good
table(CD$Condition) #Fairly Even, Look Good
table(CD$Condition, CD$Number.of.People)
table(CD$Equal.Participation) #Random Little y, will change
CD$Equal.Participation[CD$Equal.Participation == "y"] = "Y"
CD$Equal.Participation = droplevels(CD$Equal.Participation)
notyposCD = CD

#check for continuous problems, looking for extreme  numbers, and no negatives
summary(notyposCD) # Looks Good

#Missing Data
#none

#Outliers
#I don't think taking out someones guess as an outlier is appropriate analysis

#Assumptions
#Linearity
randomCD = rchisq(nrow(notyposCD), 7)
fakeCD = lm(randomCD~., data=notyposCD[ , -c(1,2,3,4)])
standardizedCD = rstudent(fakeCD)
qqnorm(standardizedCD)
abline(0,1) #Good

#Normality
skewness(notyposCD[ , -c(1,2,3,4)], na.rm=TRUE)
kurtosis(notyposCD[ , -c(1,2,3,4)], na.rm=TRUE)
hist(standardizedCD, breaks=15) #A Bit Skewed, but CLT

#homogeneity and homoscedaticity
fitvaluesCD = scale(fakeCD$fitted.values)
plot(fitvaluesCD, standardizedCD) 
abline(0,0)
abline(v = 0)

# Merging -----------------------------------------------------------------

master = rbind(notyposAB, notyposCD)
#View(master)

# Melting -----------------------------------------------------------------

library(reshape)
longmaster = melt(master, 
                   id = c("Group.Name", "Number.of.People", "Condition", "Equal.Participation"), 
                   measured = c("Cigarette", "Smoke", "Ash", "Butt", "Stomach", 
                                "Button", "Ache", "Dancer", "Fat", "Hair", "Tooth", 
                                "Comb", "Paint", "Store", "Food", "Shopping","Bag", "List", 
                                "Shampoo", "Hair.1", "Air", "Cold", "Cool", "Washer","Hair.2", 
                                "Clothes", "Heat", "Laundry", "Jump", "Ski", "Rabbit", "Bunny", 
                                "Scotch", "Paper", "Bed", "Blanket", "Music", "White", "Pillow", 
                                "Cover"))
#Rename Columns
colnames(longmaster)[5] = "Word"
colnames(longmaster)[6] = "Correct"
#View(longmaster)

#read in the other data
#make sure the newdata has a column called Word
#make sure Hair and Hair.1 are both rows 

colnames(newdata)[1] = "Word"
longmaster = merge(longmaster, newdata,
                   by.x = "Word")

longmaster$Number.of.People[is.na(longmaster$Number.of.People)] = 1
part_temp = longmaster[ !duplicated(longmaster$Group.Name) , ]
```

## Participants

Participants were recruited from the Psychology Department at a large Midwestern university using an online participant management system. They were given course credit for their participation in the study. Participants were assigned to work alone (`r nrow(part_temp[grep("Single", part_temp$Condition) , ])`) or in groups (`r nrow(part_temp[grep("Group", part_temp$Condition) , ])` groups, `r sum(part_temp$Number.of.People[grep("Group", part_temp$Condition)])`) with a total of `r nrow(part_temp)` sessions and `r sum(part_temp$Number.of.People)` completing the study. No other demographic information was collected. 

## Materials

Stimuli were selected from the University of South Florida Free Association Database [@Nelson2004]. Free association norms were created by asking participants to list the first word that comes to mind given a cue word. For example, when shown the cue *lost*, many participants will then list the target word *found*. These responses were collected over many participants and use the create a probability of eliciting the target word given a cue word called forward strength (FSG).  

Stimuli will be selected from the Nelson et al. (2004) free association database.  In Family Feud, participants are asked to guess items “100 people on the street” listed when given a category label.  For example, when given the category CHORES, many people listed DISHES, LAUNDRY, and VACUUMING.  The free association database was collected in roughly the same format.  Participants were given a concept (LOST) and asked to list the first word that came to mind (FOUND).  These responses were then averaged over participants to create a probability of each response or the number of times, out of 100, that someone would say that word.  Category labels for the game will be selected from the database with at least four matching target words.  The cue word will be used for the rounds, and each target word will be used for participants to guess. 

## Procedure

four different versions 
two of the versions included single participants versus groups of participants (a and d)

### Version A

guess the words, no numbers present
three guesses wrong and we moved on
most matches a traditional free association task 

### Version B

guess the words, numbers were present
three guesses wrong and we moved on

### Version C

guess the numbers, words were in numerical order
1 guess to get it right and they were considered right if it was within five points

### Version D

guess the numbers, words were NOT in numerical order
1 guess to get it right and they were considered right if it was within five points
most matches a JAM task 

First, participants will be given a consent form to sign.  An experimenter will be with the participant at all times to keep score and be the game show host.  The rules of the game will be explained to the participant as follows: “You will be playing Family Feud for your experimental credit today.  We asked 100 people to say the first thing they thought of when given each category you are going to see today.  For example, when we gave people the word “steak” many of them listed “sauce, cow, sirloin”.  In the following rounds, you will guess what words people listed.  (OR you will guess the number of people who listed each word)  You will receive points for your correct guesses.  Try to beat the high lab score!”

Participants will be in one of three conditions:
•	Regular Family Feud:  This condition is played like the game show.  Participants are given the category label and asked to guess four words that people listed.  They are given three strikes at guessing before moving onto the next round.  When they guess a correct word, they are shown the word and points on a computer screen.  The experimenter will keep score.
•	Numbered Family Feud:  This condition is the same as above, with one exception.  Participants will be able to see the number of people who listed each word next to the ? on each category label.  This condition will examine if participants have an easier or harder time guessing with the scores listed.
•	Reverse Family Feud:  This condition is played where participants are required the guess the number of people who listed each word under a category, mirroring the judgments of associative memory task previously used by the researcher.  They will be told to guess within 10-20 people of the words (this number will be pilot tested by the lab assistants to find the range that allows participants to “win”).  
The research assistants will pilot test all three conditions to come up with high scores for the game.  The scores will be biased lower, so that participants can almost always score in the high score range.  These scores will be posted in the lab for participants to try to beat.  The first experiment will test participants individually, to eliminate any social facilitation and create a control group.  The second experiment will test participants in pairs/threes to analyze judgments in groups.


## Data analysis

Going to talk here about MLM and Log regression as the analyses of choice because they are the most appropriate. 

# Results

## Hypothesis 1
•	Version A versus B – would answer if the number helped them guess or not
o	Multilevel log regression 
o	Random: participant, word?
o	IVs: Version, Points (sort of L, M, H words)
o	DV: correct (1) versus incorrect (0)

```{r A versus B}
hyp3 = subset(longmaster, Condition == "B Single" | Condition == "A.1 Single")
model5 = glm(Correct ~ 1, 
             data = hyp3, 
             family = binomial(), 
             na.action = "na.omit")
summary(model5)

##Model 2a = random intercept (participant) 
model6 = glmer(Correct ~ 1 + (1|Group.Name), 
             data = hyp3, 
             na.action = "na.omit",
             family = binomial,
             control = glmerControl(optimizer = "bobyqa"),
             nAGQ = 1)
summary(model6)

model6.1 = glmer(Correct ~ 1 + (1|Group.Name) + (1|Word), 
               data = hyp3, 
               na.action = "na.omit",
               family = binomial,
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 1)
summary(model6.1)

model6.2 = glmer(Correct ~ 1 + (1|Word), 
               data = hyp3, 
               na.action = "na.omit",
               family = binomial,
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 1)
summary(model6.2)

#Compare
anova(model5, model6, model6.1) 
anova(model5, model6.1)
anova(model5, model6.2, model6.1)

##main effects
model7 = glmer(Correct ~ Condition + Points + (1|Group.Name) + (1|Word), 
             data = hyp3, 
             na.action = "na.omit",
             family = binomial,
             control = glmerControl(optimizer = "bobyqa"),
             nAGQ = 1)
summary(model7)

##interactions
model8 = glmer(Correct ~ Condition * Points + (1|Group.Name) + (1|Word), 
             data = hyp3, 
             na.action = "na.omit",
             family = binomial,
             control = glmerControl(optimizer = "bobyqa"),
             nAGQ = 1)
summary(model8)

anova(model7, model8)

###simple slopes 
#A Single Slope
hyp4 = subset(longmaster, Condition == "A.1 Single")
model3.c = glmer(Correct ~ Points + (1|Group.Name) + (1|Word),
               data = hyp4, 
               na.action = "na.omit",
               family = binomial,
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 1)
summary(model3.c)

#B Single Slope
hyp5 = subset(longmaster, Condition == "B Single")
model3.d = glmer(Correct ~ Points + (1|Group.Name) + (1|Word),
               data = hyp5, 
               na.action = "na.omit",
               family = binomial,
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 1)
summary(model3.d)

```


## Hypothesis 2
•	Version C versus D – would answer if we are better if they are in order or not
o	Multilevel regression 
o	Random: participant, word?
o	IVs: Version, Points (sort of L, M, H words)
o	DV: Score they guessed 

```{r C Versus D}
hyp1 = subset(longmaster, Condition == "C Singles" | Condition == "D Single")

#Intercept Only Model
model1 = gls(Correct ~ 1, 
             data = hyp1, 
             method = "ML", 
             na.action = "na.omit")
summary(model1)

#Random Intercept Only Model
model2 = lme(Correct ~ 1, 
             data = hyp1, 
             method = "ML", 
             na.action = "na.omit",
             random = ~1|Group.Name)
summary(model2)

model2.1 = lme(Correct ~ 1, 
               data = hyp1, 
               method = "ML", 
               na.action = "na.omit",
               random = list(~1|Group.Name, ~1|Word))
summary(model2.1)

model2.2 = lme(Correct ~ 1, 
               data = hyp1, 
               method = "ML", 
               na.action = "na.omit",
               random = list(~1|Word))
summary(model2.2)

#Compare One and Two
anova(model1, model2, model2.1) ## both is better than just group name
anova(model1, model2.1) ##both better than nothing
anova(model1, model2.2, model2.1) ##model 2.1 is actually worse than model 2.2 so just by word

#Add Fixed Effects to the Model
model3 = lme(Correct ~ Condition + Points, 
             data = hyp1, 
             method = "ML", 
             na.action = "na.omit",             
             random = list(~1|Group.Name, ~1|Word))
summary(model3)

#Compare One, Two and Three
anova(model2.2, model3)

##Interactions
model4 = lme(Correct ~ Condition * Points, 
             data = hyp1, 
             method = "ML", 
             na.action = "na.omit",
             random = list(~1|Group.Name, ~1|Word))
summary(model4)

anova(model3, model4)

##simple slopes
#group c slope
#run model 3 on just group c
hyp2 = subset(longmaster, Condition == "C Singles")
model3.c = lme(Correct ~ Points,
             data = hyp2, 
             method = "ML", 
             na.action = "na.omit",
             random = list(~1|Group.Name, ~1|Word))
summary(model3.c)

#group d slope 
#run model 3 on just group d
hyp3 = subset(longmaster, Condition == "D Single")
model3.d = lme(Correct ~ Points,
               data = hyp3, 
               method = "ML", 
               na.action = "na.omit",
               random = list(~1|Group.Name, ~1|Word))
summary(model3.d)

##group c
plot(hyp2$Points, hyp2$Correct)
##group d
plot(hyp3$Points, hyp3$Correct)
```


## Hypothesis 3
•	Version A singles versus Groups
o	Multilevel log regression 
o	Random: participant, word?
o	IVs: Singles/Groups, Points (sort of L, M, H words)
o	DV: correct (1) versus incorrect (0) 

```{r}
hyp6 = subset(longmaster, Condition == "A Group" | Condition == "A.1 Single")
model9 = glm(Correct ~ 1, 
             data = hyp6, 
             family = binomial(), 
             na.action = "na.omit")
summary(model9) #AIC is 10049

##Model 2a = random intercept (participant) 
model10 = glmer(Correct ~ (1|Group.Name), 
                data = hyp6,
                family = binomial,
                control = glmerControl(optimizer = "bobyqa"),
                nAGQ = 1)
summary(model10) #AIC is 10003.7

model10.1 = glmer(Correct ~ (1|Group.Name) + (1|Word), 
                  data = hyp6,
                  family = binomial,
                  control = glmerControl(optimizer = "bobyqa"),
                  nAGQ = 1)
summary(model10.1) #AIC is 7491.9 ****, both is best model

model10.2 = glmer(Correct ~ (1|Word), 
                  data = hyp6,
                  family = binomial,
                  control = glmerControl(optimizer = "bobyqa"),
                  nAGQ = 1)
summary(model10.2) #AIC is 7631

#Compare, Doesn't give much info
anova(model9, model10, model10.1) 
anova(model9, model10.1)
anova(model9, model10.2, model10.1)

##main effects
model11 = glmer(Correct ~ Condition + Points + (1|Group.Name) + (1|Word) ,
                data = hyp6,
                family = binomial,
                control = glmerControl(optimizer = "bobyqa"),
                nAGQ = 1)
summary(model11) #AIC is 7373.2, all significant 

##interactions
model11.1 = glmer(Correct ~ Condition * Points + (1|Group.Name) + (1|Word), 
                  data = hyp6,
                  family = binomial,
                  control = glmerControl(optimizer = "bobyqa"),
                  nAGQ = 1)
summary(model11.1) #AIC is 7368.7, all significant

anova(model11, model11.1) ##significant

###simple slopes 
#A Single Slope
hyp7 = subset(longmaster, Condition == "A.1 Single")
model11.c = glmer(Correct ~ Points + (1|Group.Name) + (1|Word),
                  data = hyp7,
                  family = binomial,
                  control = glmerControl(optimizer = "bobyqa"),
                  nAGQ = 1)
summary(model11.c) #AIC is 2650.5, all significant

#A Group
hyp8 = subset(longmaster, Condition == "A Group")
model11.d = glmer(Correct ~ Points + (1|Group.Name) + (1|Word),
                  data = hyp8,
                  family = binomial,
                  control = glmerControl(optimizer = "bobyqa"),
                  nAGQ = 1) 
summary(model11.d) #AIC is 4775.7, significant

```

## Hypothesis 4
•	Version D singles versus Groups
o	Multilevel regression 
o	Random: participant, word?
o	IVs: Singles/groups, Points (sort of L, M, H words)
o	DV: Score they guessed 

```{r}
hyp9 = subset(longmaster, Condition == "D Group" | Condition == "D Single")

#Intercept Only Model
model12 = gls(Correct ~ 1, 
             data = hyp9, 
             method = "ML", 
             na.action = "na.omit")
summary(model12) #AIC is 17228.86

#Random Intercept Only Model
model13 = lme(Correct ~ 1, 
             data = hyp9, 
             method = "ML", 
             na.action = "na.omit",
             random = ~1|Group.Name)
summary(model13) #AIC is 17206.12

model13.1 = lme(Correct ~ 1, 
               data = hyp9, 
               method = "ML", 
               na.action = "na.omit",
               random = list(~1|Group.Name, ~1|Word))
summary(model13.1) #AIC is 17208.12, really close to model13

model13.2 = lme(Correct ~ 1, 
               data = hyp9, 
               method = "ML", 
               na.action = "na.omit",
               random = list(~1|Word))
summary(model13.2) #AIC is 16694.06 ****, only word is best model

#Compare Thirteen and Twelve
anova(model12, model13, model13.1) # model 3 is significant
anova(model12, model13.1) #model 3.1 is significant
anova(model12, model13.2, model13.1) #All significant

#Add Fixed Effects to the Model
model14 = lme(Correct ~ Condition + Points, 
             data = hyp9, 
             method = "ML", 
             na.action = "na.omit",             
             random = list(~1|Group.Name, ~1|Word))
summary(model14)

#Compare One, Two and Three
anova(model, model14)

##Interactions
model15 = lme(Correct ~ Condition * Points, 
             data = hyp9, 
             method = "ML", 
             na.action = "na.omit",
             random = list(~1|Group.Name, ~1|Word)) 
summary(model15)

anova(model14, model15)

###Simple Slopes
#D Single
hyp10 = subset(longmaster, Condition == "D Single")
model16 = lme(Correct ~ Points,
               data = hyp10, 
               method = "ML", 
               na.action = "na.omit",
               random = list(~1|Group.Name, ~1|Word))
summary(model16) #AIC is 16735.43, significant

#D Group
hyp11 = subset(longmaster, Condition == "D Group")
model17 = lme(Correct ~ Points,
               data = hyp11, 
               method = "ML", 
               na.action = "na.omit",
               random = list(~1|Group.Name, ~1|Word))
summary(model17) #AIC is 21488.97, significant
```

# Discussion


\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
