---
title             : "Gamifying Judgments of Associative Memory"
shorttitle        : "JAM GAME"

author: 
  - name          : "Erin M. Buchanan"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "326 S. Market St., Harrisburg, PA, 17101"
    email         : "ebuchanan@harrisburgu.edu"
  - name          : "Abigail Van Nuland"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Missouri State University"

authornote: |
  Erin M. Buchanan is a Professor of Cognitive Analytics at Harrisburg University of Science and Techonology, and Abigail Van Nuland is a Masters Degree candidate at Missouri State Univeristy. 

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "judgments, word association, metacognition"

#bibliography      : ["r-references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
replace_ampersands: yes
csl               : apa6.csl
---

We are going to write an introduction here about JAM, association, and stuff. 

1) In a traditional free association task, people guess the words...would the numbers help? (a v b)
2) In a JAM task with multiple guesses, they would normally see the words, would expect them to be able to guess better if they know it's descending order, so the D condition would match the normal JAM slope and C should be better (this answers the bounded question).
3) For the non-numbers condition, see if singles or groups are better. Shouldn't more heads be better than one?
4) For the normal JAM task, see if groups are better than singles at guessing the numbers. 

Judgments of associative memory are notoriously poor (Buchanan, 2009; Maki, 2007), where participants over estimate the relationship between word pairs.  In the judgment task, participants are given two words (LOST-FOUND) and asked to rate how many people out of a 100 would list the second word if given the first word.  Participants cannot tell the difference between low and high frequency pairs and tend to judge pairs higher than they should.  The psycholinguistics lab has tried to correct these memory judgments by giving participants various instructions (Buchanan & Maki, in preparation), changing the scales for judgments (Buchanan, data analysis), changing the judgment type (Maki & Buchanan, in preparation), and having participants judge their own ratings over time (Buchanan, data collection).  These manipulations have shown a small effect on judgment ability, mainly to reduce the overall bias to select very large numbers.  The current protocol will examine if judgments are more accurate when the experimental task is more interesting and engaging.  We will be using the game show Family Feud as the experimental procedure because the game show closely matches the judgments of memory paradigm currently used.

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE)
# Load Libraries ----------------------------------------------------------
library("papaja")
library(moments)
library(reshape)
library(nlme)
library(lme4)
```

# Method

```{r Upload_Data, include = FALSE}
#upload data sets
AB = read.csv("AB_FF_Data.csv")
#View(AB)
CD = read.csv("CD_FF_Data.csv")
#View(CD)
newdata = read.csv("Points.csv")

newdata$cue = c(rep("ashtray", 4),
                rep("belly", 5), 
                rep("brush", 4),
                rep("grocery", 5),
                rep("conditioner", 5),
                rep("dryer", 5),
                rep("hop", 5),
                rep("sheet", 7))
```

```{r data_screening, include=FALSE}

# Data Screening ----------------------------------------------------------
###AB Set###
##Accuracy
#Categorical Variables
table(AB$Number.of.People) #Includes One Group of One? (delete)
table(AB$Condition, AB$Number.of.People)
AB$Condition[AB$Number.of.People == 1] = "A.1 Single"
table(AB$Condition) #Uneven But No Typos
table(AB$Equal.Participation) #*Will Make No Missing Data
notyposAB = AB

#check for continuous problems, making sure only options are 1 and 0
summary(notyposAB) #Looks Good

#Missing Data
#none

#Outliers
#Don't See How we could do an outlier ananlysis (0 and 1 only options)

##Assumptions
#Linearity
random = rchisq(nrow(notyposAB), 7)
fakeAB = lm(random~., data=notyposAB[ , -c(1,2,3,4)])
standardizedAB = rstudent(fakeAB)
qqnorm(standardizedAB)
abline(0,1) 

#Normality
skewness(notyposAB[ , -c(1,2,3,4)], na.rm=TRUE)
kurtosis(notyposAB[ , -c(1,2,3,4)], na.rm=TRUE)
hist(standardizedAB, breaks=15) #A Bit Skewed, but CLT

##homogeneity and homoscedaticity
fitvalues = scale(fakeAB$fitted.values)
plot(fitvalues, standardizedAB) 
abline(0,0)
abline(v = 0)

###CD Set###
#Accuracy
#Categorical Variables
table(CD$Number.of.People) #Looks Good
table(CD$Condition) #Fairly Even, Look Good
table(CD$Condition, CD$Number.of.People)
table(CD$Equal.Participation) #Random Little y, will change
CD$Equal.Participation[CD$Equal.Participation == "y"] = "Y"
CD$Equal.Participation = droplevels(CD$Equal.Participation)
notyposCD = CD

#check for continuous problems, looking for extreme  numbers, and no negatives
summary(notyposCD) # Looks Good

#Missing Data
#none

#Outliers
#I don't think taking out someones guess as an outlier is appropriate analysis

#Assumptions
#Linearity
randomCD = rchisq(nrow(notyposCD), 7)
fakeCD = lm(randomCD~., data=notyposCD[ , -c(1,2,3,4)])
standardizedCD = rstudent(fakeCD)
qqnorm(standardizedCD)
abline(0,1) #Good

#Normality
skewness(notyposCD[ , -c(1,2,3,4)], na.rm=TRUE)
kurtosis(notyposCD[ , -c(1,2,3,4)], na.rm=TRUE)
hist(standardizedCD, breaks=15) #A Bit Skewed, but CLT

#homogeneity and homoscedaticity
fitvaluesCD = scale(fakeCD$fitted.values)
plot(fitvaluesCD, standardizedCD) 
abline(0,0)
abline(v = 0)

# Merging -----------------------------------------------------------------

master = rbind(notyposAB, notyposCD)
#View(master)

# Melting -----------------------------------------------------------------

library(reshape)
longmaster = melt(master, 
                   id = c("Group.Name", "Number.of.People", "Condition", "Equal.Participation"), 
                   measured = c("Cigarette", "Smoke", "Ash", "Butt", "Stomach", 
                                "Button", "Ache", "Dancer", "Fat", "Hair", "Tooth", 
                                "Comb", "Paint", "Store", "Food", "Shopping","Bag", "List", 
                                "Shampoo", "Hair.1", "Air", "Cold", "Cool", "Washer","Hair.2", 
                                "Clothes", "Heat", "Laundry", "Jump", "Ski", "Rabbit", "Bunny", 
                                "Scotch", "Paper", "Bed", "Blanket", "Music", "White", "Pillow", 
                                "Cover"))
#Rename Columns
colnames(longmaster)[5] = "Word"
colnames(longmaster)[6] = "Correct"
#View(longmaster)

#read in the other data
#make sure the newdata has a column called Word
#make sure Hair and Hair.1 are both rows 

colnames(newdata)[1] = "Word"
longmaster = merge(longmaster, newdata,
                   by.x = "Word")

#View(table(longmaster$Group.Name))

longmaster$Number.of.People[is.na(longmaster$Number.of.People)] = 1
part_temp = longmaster[ !duplicated(longmaster$Group.Name) , ]
```

## Participants

Participants were recruited from the Psychology Department at a large Midwestern university using an online participant management system. They were given course credit for their participation in the study. Participants were assigned to work alone (*n* = `r nrow(part_temp[grep("Single", part_temp$Condition) , ])`) or in groups ($n_{groups}$ = `r nrow(part_temp[grep("Group", part_temp$Condition) , ])`, *n* = `r sum(part_temp$Number.of.People[grep("Group", part_temp$Condition)])`) with a total of `r nrow(part_temp)` sessions and `r sum(part_temp$Number.of.People)` completing the study. No other demographic information was collected. 

## Materials

Stimuli were selected from the University of South Florida Free Association Database [@Nelson2004]. These free association norms were created by asking participants to list the first word that comes to mind given a cue word. For example, when shown the cue *lost*, many participants will then list the target word *found*. These responses were collected over many participants and then used the create a probability of eliciting the target word given a cue word called forward strength (FSG). The purpose of this study was to examine free association and judgments of associative memory over multiple cues, and therefore, cues with at least four matching target words were selected. For example, when given the cue *conditioner*, participants might list *shampoo* (FSG = .455), *hair* (FSG = .325), and *air* (FSG = .110). Cues with at least one target in each of the forward strength ranges of .40-.60, .20-.40, and <.20 were selected. Eight cue words were selected with an average of `r printnum(mean(table(newdata$cue)))` target words paired with each cue (*SD* = `r printnum(sd(table(newdata$cue)))`). The average forward strength for high strength targets was `r printnum(mean(newdata$Points[newdata$Points >= 40])/100)` (*SD* = `r printnum(sd(newdata$Points[newdata$Points >= 40])/100)`), medium strength targets was `r printnum(mean(newdata$Points[newdata$Points < 40 & newdata$Points >=20])/100)` (*SD* = `r printnum(sd(newdata$Points[newdata$Points < 40 & newdata$Points >=20])/100)`), and low strength targets was `r printnum(mean(newdata$Points[newdata$Points < 20])/100)` (*SD* = `r printnum(sd(newdata$Points[newdata$Points < 20])/100)`). The complete materials can be found online at https://osf.io/83bkt/. 

## Procedure

Multiple versions of the study were created with the eight cue-target lists described above. These were compiled into a powerpoint document that emulated a game of Family Feud. Family Feud is a game show that gives contestants category labels and asks them to list the most popular answers that people would say given the category label. For example, on the show, contestants would hear that 100 people were surveyed with the question: "Name something you might eat with a hamburger." The contestants would then guess the most popular answers (*french fries, soup, salad*) and win points based on naming the most popular responses.

ho try to match the answers given to survey questions asked to groups of people (typically 100 people in the group)

An experimenter will be with the participant at all times to keep score and be the game show host.  The rules of the game will be explained to the participant as follows: "You will be playing Family Feud for your experimental credit today.  We asked 100 people to say the first thing they thought of when given each category you are going to see today.  For example, when we gave people the word "steak" many of them listed "sauce, cow, sirloin".  In the following rounds, you will guess what words people listed.  (OR you will guess the number of people who listed each word)  You will receive points for your correct guesses.  Try to beat the high lab score!"

four different versions 
two of the versions included single participants versus groups of participants (a and d)

### Version A

guess the words, no numbers present
three guesses wrong and we moved on
most matches a traditional free association task 

### Version B

guess the words, numbers were present
three guesses wrong and we moved on

### Version C

guess the numbers, words were in numerical order
1 guess to get it right and they were considered right if it was within five points

### Version D

guess the numbers, words were NOT in numerical order
1 guess to get it right and they were considered right if it was within five points
most matches a JAM task 

Participants will be in one of three conditions:
•	Regular Family Feud:  This condition is played like the game show.  Participants are given the category label and asked to guess four words that people listed.  They are given three strikes at guessing before moving onto the next round.  When they guess a correct word, they are shown the word and points on a computer screen.  The experimenter will keep score.
•	Numbered Family Feud:  This condition is the same as above, with one exception.  Participants will be able to see the number of people who listed each word next to the ? on each category label.  This condition will examine if participants have an easier or harder time guessing with the scores listed.
•	Reverse Family Feud:  This condition is played where participants are required the guess the number of people who listed each word under a category, mirroring the judgments of associative memory task previously used by the researcher.  They will be told to guess within 10-20 people of the words (this number will be pilot tested by the lab assistants to find the range that allows participants to “win”).  
The research assistants will pilot test all three conditions to come up with high scores for the game.  The scores will be biased lower, so that participants can almost always score in the high score range.  These scores will be posted in the lab for participants to try to beat.  The first experiment will test participants individually, to eliminate any social facilitation and create a control group.  The second experiment will test participants in pairs/threes to analyze judgments in groups.


## Data analysis

Going to talk here about MLM and Log regression as the analyses of choice because they are the most appropriate. 

# Results

## Hypothesis 1
•	Version A versus B – would answer if the number helped them guess or not
o	Multilevel log regression 
o	Random: participant, word?
o	IVs: Version, Points (sort of L, M, H words)
o	DV: correct (1) versus incorrect (0)

```{r A_versus_B, include=FALSE}
hyp3 = subset(longmaster, Condition == "B Single" | Condition == "A.1 Single")
model5 = glm(Correct ~ 1, 
             data = hyp3, 
             family = binomial(), 
             na.action = "na.omit")
summary(model5)

##Model 2a = random intercept (participant) 
model6 = glmer(Correct ~ 1 + (1|Group.Name), 
             data = hyp3, 
             na.action = "na.omit",
             family = binomial,
             control = glmerControl(optimizer = "bobyqa"),
             nAGQ = 1)
summary(model6)

model6.1 = glmer(Correct ~ 1 + (1|Group.Name) + (1|Word), 
               data = hyp3, 
               na.action = "na.omit",
               family = binomial,
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 1)
summary(model6.1)

model6.2 = glmer(Correct ~ 1 + (1|Word), 
               data = hyp3, 
               na.action = "na.omit",
               family = binomial,
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 1)
summary(model6.2)

#Compare
anova(model5, model6, model6.1) 
anova(model5, model6.1)
anova(model5, model6.2, model6.1)

##main effects
model7 = glmer(Correct ~ Condition + Points + (1|Group.Name) + (1|Word), 
             data = hyp3, 
             na.action = "na.omit",
             family = binomial,
             control = glmerControl(optimizer = "bobyqa"),
             nAGQ = 1)
summary(model7)

##interactions
model8 = glmer(Correct ~ Condition * Points + (1|Group.Name) + (1|Word), 
             data = hyp3, 
             na.action = "na.omit",
             family = binomial,
             control = glmerControl(optimizer = "bobyqa"),
             nAGQ = 1)
summary(model8)

anova(model7, model8)

###simple slopes 
#A Single Slope
hyp4 = subset(longmaster, Condition == "A.1 Single")
model3.c = glmer(Correct ~ Points + (1|Group.Name) + (1|Word),
               data = hyp4, 
               na.action = "na.omit",
               family = binomial,
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 1)
summary(model3.c)

#B Single Slope
hyp5 = subset(longmaster, Condition == "B Single")
model3.d = glmer(Correct ~ Points + (1|Group.Name) + (1|Word),
               data = hyp5, 
               na.action = "na.omit",
               family = binomial,
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 1)
summary(model3.d)
```

```{r ab_table, results = 'asis', echo = FALSE}
####table set up####
##create a blank table
tableprint1 = matrix(NA, nrow = 7, ncol = 6)
colnames(tableprint1) = c("Model", "Predictor", "$b$", "$SE$", "$z$", "$p$")

tableprint1[1:2, 1] = "Main Effects"
tableprint1[1:2, 2] = c("A vs B", "Points")
tableprint1[1:2, 3:6] = coef(summary(model7))[-1, ]
tableprint1[3:5, 1] = "Interactions"
tableprint1[3:5, 2] = c("A vs B", "Points", "Group:Points")
tableprint1[3:5 , 3:6 ] = coef(summary(model8))[-1, ]
tableprint1[6, 1] = "Simple Slope A"
tableprint1[6, 2] = c("Points")
tableprint1[6 , 3:6 ] = coef(summary(model3.c))[-1, ]
tableprint1[7, 1] = "Simple Slope B"
tableprint1[7, 2] = c("Points")
tableprint1[7 , 3:6 ] = coef(summary(model3.d))[-1, ]

#APA format
tableprint1[ , 3:5] = printnum(as.numeric(tableprint1[ , 3:5]))
tableprint1[ , 6] = printp(as.numeric(tableprint1[ , 6]))

apa_table(as.data.frame(tableprint1),
          note = "STUFF", 
          caption = "HEADER",
          #latex = T,
          #escape = F,
          align = c("l", rep("c", 5)))

#View(tableprint1)
#works

#coef(summary(model7))
#coef(summary(model8))
#coef(summary(model3.c))
#coef(summary(model3.d))
```

## Hypothesis 2
•	Version C versus D – would answer if we are better if they are in order or not
o	Multilevel regression 
o	Random: participant, word?
o	IVs: Version, Points (sort of L, M, H words)
o	DV: Score they guessed 

```{r C_Versus_D, include=FALSE}
hyp1 = subset(longmaster, Condition == "C Singles" | Condition == "D Single")

#Intercept Only Model
model1 = gls(Correct ~ 1, 
             data = hyp1, 
             method = "ML", 
             na.action = "na.omit")
summary(model1)

#Random Intercept Only Model
model2 = lme(Correct ~ 1, 
             data = hyp1, 
             method = "ML", 
             na.action = "na.omit",
             random = ~1|Group.Name)
summary(model2)

model2.1 = lme(Correct ~ 1, 
               data = hyp1, 
               method = "ML", 
               na.action = "na.omit",
               random = list(~1|Group.Name, ~1|Word))
summary(model2.1)

model2.2 = lme(Correct ~ 1, 
               data = hyp1, 
               method = "ML", 
               na.action = "na.omit",
               random = list(~1|Word))
summary(model2.2)

#Compare One and Two
anova(model1, model2, model2.1) ## both is better than just group name
anova(model1, model2.1) ##both better than nothing
anova(model1, model2.2, model2.1) ##model 2.1 is actually worse than model 2.2 so just by word

#Add Fixed Effects to the Model
model3 = lme(Correct ~ Condition + Points, 
             data = hyp1, 
             method = "ML", 
             na.action = "na.omit",             
             random = list(~1|Group.Name, ~1|Word))
summary(model3)

#Compare One, Two and Three
anova(model2.2, model3)

##Interactions
model4 = lme(Correct ~ Condition * Points, 
             data = hyp1, 
             method = "ML", 
             na.action = "na.omit",
             random = list(~1|Group.Name, ~1|Word))
summary(model4)

anova(model3, model4)

##simple slopes
#group c slope
#run model 3 on just group c
hyp2 = subset(longmaster, Condition == "C Singles")
model3.c = lme(Correct ~ Points,
             data = hyp2, 
             method = "ML", 
             na.action = "na.omit",
             random = list(~1|Group.Name, ~1|Word))
summary(model3.c)

#group d slope 
#run model 3 on just group d
hyp3 = subset(longmaster, Condition == "D Single")
model3.d = lme(Correct ~ Points,
               data = hyp3, 
               method = "ML", 
               na.action = "na.omit",
               random = list(~1|Group.Name, ~1|Word))
summary(model3.d)

##group c
plot(hyp2$Points, hyp2$Correct)
##group d
plot(hyp3$Points, hyp3$Correct)
```

```{r cd_table, results = 'asis', echo = FALSE}
####table set up####
##create a blank table
tableprint2 = matrix(NA, nrow = 7, ncol = 7)
colnames(tableprint2) = c("Model", "Predictor", "$b$", "$SE$", "$df$", "$t$", "$p$")

tableprint2[1:2, 1] = "Main Effects"
tableprint2[1:2, 2] = c("C vs D", "Points")
tableprint2[1:2 , 3:7] = summary(model3)$tTable[-1 , ]
tableprint2[3:5, 1] = "Interaction"
tableprint2[3:5, 2] = c("C vs D", "Points", "Group: Points")
tableprint2[3:5 , 3:7 ] = summary(model4)$tTable[-c(1) , ]
tableprint2[6, 1] = "Simple Slope"
tableprint2[6, 2:3] = c("Points")
tableprint2[6 , 3:7 ] = summary(model3.c)$tTable[-1 , ]  ##I think there are two model3.c
tableprint2[7, 1] = "Simple Slope"
tableprint2[7, 2:3] = c("Points")
tableprint2[7 , 3:7 ] = summary(model3.d)$tTable[-1 , ]

#APA Format
tableprint2[ , 3:6] = printnum(as.numeric(tableprint2[ , 3:6]))
tableprint2[ , 7] = printp(as.numeric(tableprint2[ , 7]))

#View(tableprint2)
#works

#summary(model3)$tTable
#summary(model4)$tTable
#summary(model3.c)$tTable
#summary(model3.d)$tTable
```

## Hypothesis 3
•	Version A singles versus Groups
o	Multilevel log regression 
o	Random: participant, word?
o	IVs: Singles/Groups, Points (sort of L, M, H words)
o	DV: correct (1) versus incorrect (0) 

```{r A_singles_groups, include=FALSE}
hyp6 = subset(longmaster, Condition == "A Group" | Condition == "A.1 Single")
model9 = glm(Correct ~ 1, 
             data = hyp6, 
             family = binomial(), 
             na.action = "na.omit")
summary(model9) #AIC is 10049

##Model 2a = random intercept (participant) 
model10 = glmer(Correct ~ (1|Group.Name), 
                data = hyp6,
                family = binomial,
                control = glmerControl(optimizer = "bobyqa"),
                nAGQ = 1)
summary(model10) #AIC is 10003.7

model10.1 = glmer(Correct ~ (1|Group.Name) + (1|Word), 
                  data = hyp6,
                  family = binomial,
                  control = glmerControl(optimizer = "bobyqa"),
                  nAGQ = 1)
summary(model10.1) #AIC is 7491.9 ****, both is best model

model10.2 = glmer(Correct ~ (1|Word), 
                  data = hyp6,
                  family = binomial,
                  control = glmerControl(optimizer = "bobyqa"),
                  nAGQ = 1)
summary(model10.2) #AIC is 7631

#Compare, Doesn't give much info
anova(model9, model10, model10.1) 
anova(model9, model10.1)
anova(model9, model10.2, model10.1)

##main effects
model11 = glmer(Correct ~ Condition + Points + (1|Group.Name) + (1|Word) ,
                data = hyp6,
                family = binomial,
                control = glmerControl(optimizer = "bobyqa"),
                nAGQ = 1)
summary(model11) #AIC is 7373.2, all significant 

##interactions
model11.1 = glmer(Correct ~ Condition * Points + (1|Group.Name) + (1|Word), 
                  data = hyp6,
                  family = binomial,
                  control = glmerControl(optimizer = "bobyqa"),
                  nAGQ = 1)
summary(model11.1) #AIC is 7368.7, all significant

anova(model11, model11.1) ##significant

###simple slopes 
#A Single Slope
hyp7 = subset(longmaster, Condition == "A.1 Single")
model11.c = glmer(Correct ~ Points + (1|Group.Name) + (1|Word),
                  data = hyp7,
                  family = binomial,
                  control = glmerControl(optimizer = "bobyqa"),
                  nAGQ = 1)
summary(model11.c) #AIC is 2650.5, all significant

#A Group
hyp8 = subset(longmaster, Condition == "A Group")
model11.d = glmer(Correct ~ Points + (1|Group.Name) + (1|Word),
                  data = hyp8,
                  family = binomial,
                  control = glmerControl(optimizer = "bobyqa"),
                  nAGQ = 1) 
summary(model11.d) #AIC is 4775.7, significant

```

```{r a_table, results = 'asis', echo = FALSE}
####table set up####
##create a blank table
tableprint3 = matrix(NA, nrow = 7, ncol = 6)
colnames(tableprint3) = c("Model", "Predictor", "$b$", "$SE$", "$z$", "$p$")

tableprint3[1:2, 1] = "Main Effects"
tableprint3[1:2, 2] = c("A singles vs A groups", "Points")
tableprint3[1:2 , 3:6 ] = coef(summary(model11))[-1, ] 
tableprint3[3:5, 1] = "Interactions"
tableprint3[3:5, 2] = c("A singles vs A groups", "Points", "Groups: Points")
tableprint3[3:5 , 3:6 ] = coef(summary(model11.1))[-c(1), ] 
tableprint3[6, 1] = "Simple Slope"
tableprint3[6, 2] = c("Points")
tableprint3[6 , 3:6 ] = coef(summary(model11.d))[-1, ] 
tableprint3[7, 1] = "Simple Slope"
tableprint3[7, 2] = c("Points")
tableprint3[7 , 3:6 ] = coef(summary(model11.c))[-1, ] 

#APA Format
tableprint3[ , 3:5] = printnum(as.numeric(tableprint3[ , 3:5]))
tableprint3[ , 6] = printp(as.numeric(tableprint3[ , 6])) # A singles, A groups Simple Slopes. Seem to be putting the Z Values in the spot of P Values, so this line will not run 

#View(tableprint3)
#works

#coef(summary(model11))
#coef(summary(model11.1))
#coef(summary(model11.d))
#coef(summary(model11.c))
```

## Hypothesis 4
•	Version D singles versus Groups
o	Multilevel regression 
o	Random: participant, word?
o	IVs: Singles/groups, Points (sort of L, M, H words)
o	DV: Score they guessed 

```{r D_singles_groups, include=FALSE}
hyp9 = subset(longmaster, Condition == "D Group" | Condition == "D Single")

#Intercept Only Model
model12 = gls(Correct ~ 1, 
             data = hyp9, 
             method = "ML", 
             na.action = "na.omit")
summary(model12) #AIC is 17228.86

#Random Intercept Only Model
model13 = lme(Correct ~ 1, 
             data = hyp9, 
             method = "ML", 
             na.action = "na.omit",
             random = ~1|Group.Name)
summary(model13) #AIC is 17206.12

model13.1 = lme(Correct ~ 1, 
               data = hyp9, 
               method = "ML", 
               na.action = "na.omit",
               random = list(~1|Group.Name, ~1|Word))
summary(model13.1) #AIC is 17208.12, really close to model13

model13.2 = lme(Correct ~ 1, 
               data = hyp9, 
               method = "ML", 
               na.action = "na.omit",
               random = list(~1|Word))
summary(model13.2) #AIC is 16694.06 ****, only word is best model

#Compare Thirteen and Twelve
anova(model12, model13, model13.1) # model 3 is significant
anova(model12, model13.1) #model 3.1 is significant
anova(model12, model13.2, model13.1) #All significant

#Add Fixed Effects to the Model
model14 = lme(Correct ~ Condition + Points, 
             data = hyp9, 
             method = "ML", 
             na.action = "na.omit",             
             random = list(~1|Group.Name, ~1|Word))
summary(model14)

#Compare One, Two and Three
anova(model13.1, model14)

##Interactions
model15 = lme(Correct ~ Condition * Points, 
             data = hyp9, 
             method = "ML", 
             na.action = "na.omit",
             random = list(~1|Group.Name, ~1|Word)) 
summary(model15)

anova(model14, model15)

###Simple Slopes
#D Single
hyp10 = subset(longmaster, Condition == "D Single")
model16 = lme(Correct ~ Points,
               data = hyp10, 
               method = "ML", 
               na.action = "na.omit",
               random = list(~1|Group.Name, ~1|Word))
summary(model16) #AIC is 16735.43, significant

#D Group
hyp11 = subset(longmaster, Condition == "D Group")
model17 = lme(Correct ~ Points,
               data = hyp11, 
               method = "ML", 
               na.action = "na.omit",
               random = list(~1|Group.Name, ~1|Word))
summary(model17) #AIC is 21488.97, significant
```

```{r d_table, results = 'asis', echo = FALSE}
####table set up####
##create a blank table
tableprint4 = matrix(NA, nrow = 7, ncol = 7)
colnames(tableprint4) = c("Model", "Predictor", "$b$", "$SE$", "$df$", "$t$", "$p$")

tableprint4[1:2, 1] = "Main Effects"
tableprint4[1:2, 2] = c("D Groups Versus Single", "Points")
tableprint4[1:2 , 3:7] = summary(model14)$tTable[-1 , ]
tableprint4[3:5, 1] = "Interaction"
tableprint4[3:5, 2] = c("D Groups Versus Single", "Points", "Group: Points")
tableprint4[3:5 , 3:7 ] = summary(model15)$tTable[-1 , ]
tableprint4[6, 1] = "Simple Slope"
tableprint4[6, 2] = c("Points")
tableprint4[6 , 3:7 ] = summary(model17)$tTable[-1 , ]
tableprint4[7, 1] = "Simple Slope"
tableprint4[7, 2] = c("Points")
tableprint4[7 , 3:7 ] = summary(model16)$tTable[-1 , ]

#APA Format
tableprint4[ , 3:6] = printnum(as.numeric(tableprint4[ , 3:6]))
tableprint4[ , 7] = printp(as.numeric(tableprint4[ , 7])) 

#View(tableprint4)
#summary(model14)$tTable
#summary(model15)$tTable
#summary(model17)$tTable
#summary(model16)$tTable
```

# Discussion


\newpage

# References
```{r create_r-references, include=FALSE}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
